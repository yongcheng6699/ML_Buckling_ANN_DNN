{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##  A 8-Hidden Layers Architecture (Broad Search - Parametric Study)\n",
    "What is happening here?\n",
    "    [1] A deep DNN model\n",
    "    [2] Contains two lines of code to find the rsquare\n",
    "    [3] Includes lines of code on cross validation\n",
    "    [4] Include the plot of the history curves\n",
    "    \n",
    "The lower value of MAE, MSE, and RMSE implies higher accuracy of a regression model. However, a higher value of R square is considered desirable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "254ef7c0cb13d7cf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with configuration 1: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20, Hidden Layer 6=20, Hidden Layer 7=20, Hidden Layer 8=20\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Training model with configuration 2: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20, Hidden Layer 6=20, Hidden Layer 7=20, Hidden Layer 8=40\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Training model with configuration 3: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20, Hidden Layer 6=20, Hidden Layer 7=20, Hidden Layer 8=60\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Training model with configuration 4: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20, Hidden Layer 6=20, Hidden Layer 7=20, Hidden Layer 8=80\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 11ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Training model with configuration 5: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20, Hidden Layer 6=20, Hidden Layer 7=20, Hidden Layer 8=100\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Training model with configuration 6: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20, Hidden Layer 6=20, Hidden Layer 7=40, Hidden Layer 8=20\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Training model with configuration 7: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20, Hidden Layer 6=20, Hidden Layer 7=40, Hidden Layer 8=40\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Training model with configuration 8: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20, Hidden Layer 6=20, Hidden Layer 7=40, Hidden Layer 8=60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 78\u001B[0m\n\u001B[0;32m     75\u001B[0m model \u001B[38;5;241m=\u001B[39m create_model8H(p1, p2, p3, p4, p5, p6, p7, p8)\n\u001B[0;32m     77\u001B[0m \u001B[38;5;66;03m# Fit the model\u001B[39;00m\n\u001B[1;32m---> 78\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m150\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     79\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     80\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;66;03m# Evaluate the model on training, validation, and test sets\u001B[39;00m\n\u001B[0;32m     83\u001B[0m trainmse, trainmae \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(X_train, y_train, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Buckling_ANN_DNN\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Buckling_ANN_DNN\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:324\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[0;32m    323\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[1;32m--> 324\u001B[0m         \u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_begin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    325\u001B[0m         logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_function(iterator)\n\u001B[0;32m    326\u001B[0m         callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(\n\u001B[0;32m    327\u001B[0m             step, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[0;32m    328\u001B[0m         )\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Buckling_ANN_DNN\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\callback_list.py:98\u001B[0m, in \u001B[0;36mCallbackList.on_train_batch_begin\u001B[1;34m(self, batch, logs)\u001B[0m\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[0;32m     96\u001B[0m         callback\u001B[38;5;241m.\u001B[39mon_epoch_end(epoch, logs)\n\u001B[1;32m---> 98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_train_batch_begin\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, logs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     99\u001B[0m     logs \u001B[38;5;241m=\u001B[39m logs \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m callback \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np                                             \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "\n",
    "# Load the data\n",
    "bucklingdata = pd.read_csv(\"CBL_SimulationResults.csv\", encoding='cp1252')\n",
    "input_data = bucklingdata.drop(['Critical Buckling Load (N)', 'Critical Buckling Load (kN)'], axis=1)\n",
    "output_data = bucklingdata['Critical Buckling Load (kN)']\n",
    "\n",
    "# Split the data\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data,\n",
    "                                                    test_size=0.3,\n",
    "                                                    shuffle=False,\n",
    "                                                    stratify=None,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Validation data\n",
    "val_no = round(0.2 * y_train.size)\n",
    "x_val = X_train[:val_no]\n",
    "y_val = y_train[:val_no]\n",
    "\n",
    "def create_model8H(hp_layer_1, hp_layer_2, hp_layer_3, hp_layer_4, hp_layer_5, hp_layer_6, hp_layer_7, hp_layer_8):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(11,)))\n",
    "    hp_activation = 'relu'\n",
    "    hp_learning_rate = 0.001\n",
    "    model.add(Dense(hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_4, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_5, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_6, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_7, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_8, activation=hp_activation))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    # Compile your model with your optimizer, loss, and metrics\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=Adam(learning_rate = hp_learning_rate),\n",
    "                  metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "# Specify the range for neurons in the three hidden layers\n",
    "min_neurons = 20\n",
    "max_neurons = 100\n",
    "step = 20\n",
    "\n",
    "neuron_configs = []\n",
    "\n",
    "# Generate configurations with increasing neurons in all three layers\n",
    "for neurons1 in range(min_neurons, max_neurons + 1, step):\n",
    "    for neurons2 in range(min_neurons, max_neurons + 1, step):\n",
    "        for neurons3 in range(min_neurons, max_neurons + 1, step):\n",
    "            for neurons4 in range(min_neurons, max_neurons + 1, step):\n",
    "                for neurons5 in range(min_neurons, max_neurons + 1, step):\n",
    "                    for neurons6 in range(min_neurons, max_neurons + 1, step):\n",
    "                        for neurons7 in range(min_neurons, max_neurons + 1, step):\n",
    "                            for neurons8 in range(min_neurons, max_neurons + 1, step):\n",
    "                                neuron_configs.append((neurons1, neurons2, neurons3, neurons4, neurons5, neurons6, neurons7, neurons8))\n",
    "            \n",
    "results = []\n",
    "\n",
    "## Train your model for a number of epochs, with the .fit()\n",
    "## Get the performance metrics for the network and the learning curves\n",
    "# Iterate over each configuration of neurons\n",
    "for i, (p1, p2, p3, p4, p5, p6, p7, p8) in enumerate(neuron_configs):\n",
    "    print(f\"Training model with configuration {i+1}: Hidden Layer 1={p1}, Hidden Layer 2={p2}, Hidden Layer 3={p3}, Hidden Layer 4={p4}, Hidden Layer 5={p5}, Hidden Layer 6={p6}, Hidden Layer 7={p7}, Hidden Layer 8={p8}\")\n",
    "    \n",
    "    # Create the model for the current configuration\n",
    "    model = create_model8H(p1, p2, p3, p4, p5, p6, p7, p8)\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(X_train, y_train, epochs=150,\n",
    "                        validation_data=(x_val, y_val), batch_size=32,\n",
    "                        verbose=0)\n",
    "    \n",
    "    # Evaluate the model on training, validation, and test sets\n",
    "    trainmse, trainmae = model.evaluate(X_train, y_train, verbose=0)\n",
    "    valmse, valmae = model.evaluate(x_val, y_val, verbose=0)\n",
    "    testmse, testmae = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Predictions for R-squared calculation\n",
    "    train_pred = model.predict(X_train)\n",
    "    val_pred = model.predict(x_val)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate R-squared scores\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    val_r2 = r2_score(y_val, val_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    \n",
    "    # Store the evaluation metrics in a DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        'Configuration': i + 1,\n",
    "        'Hidden Layer 1 Neurons': p1,\n",
    "        'Hidden Layer 2 Neurons': p2,\n",
    "        'Hidden Layer 3 Neurons': p3,\n",
    "        'Hidden Layer 4 Neurons': p4,\n",
    "        'Hidden Layer 5 Neurons': p5,\n",
    "        'Hidden Layer 6 Neurons': p6,\n",
    "        'Hidden Layer 7 Neurons': p7,\n",
    "        'Hidden Layer 8 Neurons': p8,\n",
    "        'Train R2': train_r2,\n",
    "        'Val R2': val_r2,\n",
    "        'Test R2': test_r2,\n",
    "        'Train RMSE': math.sqrt(trainmse),\n",
    "        'Val RMSE': math.sqrt(valmse),\n",
    "        'Test RMSE': math.sqrt(testmse),\n",
    "        'Train MAE': trainmae,\n",
    "        'Val MAE': valmae,\n",
    "        'Test MAE': testmae\n",
    "    }, index=[0])\n",
    "    \n",
    "    results.append(result_df)\n",
    "\n",
    "# Concatenate all results into a single DataFrame\n",
    "final_results = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# Save the results to an Excel file\n",
    "final_results.to_excel('9HiddenLayers_VariousNeurons_Results_1stRun.xlsx', index=False)\n",
    "\n",
    "print(f\"Results saved to 9HiddenLayers_VariousNeurons_Results.xlsx\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:44:56.387024Z",
     "start_time": "2024-04-14T18:41:32.889910Z"
    }
   },
   "id": "390d8b1015ba8d0d",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### loss vs the number of epochs & MAE vs the number of epochs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46e3b0116126ea60"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_loss(loss,val_loss):\n",
    "  plt.figure()\n",
    "  plt.style.use('bmh')\n",
    "  plt.grid(False)\n",
    "  plt.plot(loss, linewidth=2)\n",
    "  plt.plot(val_loss, linewidth=2)\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper right')\n",
    "  plt.show()\n",
    "\n",
    "def plot_mae(mae,val_mae):\n",
    "  plt.figure()\n",
    "  plt.style.use('ggplot')\n",
    "  plt.grid(False)\n",
    "  plt.plot(mae, linewidth=2)\n",
    "  plt.plot(val_mae, linewidth=2)\n",
    "  plt.ylabel('MAE')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper right')\n",
    "  plt.show()\n",
    "\n",
    "train_loss = (np.array(history.history[\"loss\"]))/100\n",
    "val_loss = np.array((history.history[\"val_loss\"]))/100\n",
    "\n",
    "plot_loss(train_loss, val_loss)\n",
    "plot_mae(history.history[\"mae\"], history.history[\"val_mae\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c91f49479e67a73f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlation between the actual output and the predicted output with the training dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecad9513bef8e009"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(y_train, train_pred, s = 20, alpha=0.7, c = 'brown')\n",
    "plt.xlabel('Actual Critical Buckling Loads (kN)')\n",
    "plt.ylabel('Predicted Critical Buckling Loads (kN)')\n",
    "plt.annotate(\"R-squared = {:.3f}\".format(r2_score(y_train, train_pred)), (6, 17.5))\n",
    "plt.xlim([5, 20])\n",
    "plt.ylim([5, 20])\n",
    "plt.plot([5, 20], [5, 20])\n",
    "plt.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T16:22:22.149471Z"
    }
   },
   "id": "3fde11aebd540867",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlation between the actual output and the predicted output with the testing dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59add69d412bd5e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(y_test, test_pred, s = 20, alpha=0.7, c = 'brown')\n",
    "plt.xlabel('Actual Critical Buckling Loads (kN)')\n",
    "plt.ylabel('Predicted Critical Buckling Loads (kN)')\n",
    "plt.annotate(\"R-squared = {:.3f}\".format(r2_score(y_train, train_pred)), (5, 19))\n",
    "plt.xlim([4, 20])\n",
    "plt.ylim([4, 20])\n",
    "plt.plot([4, 20], [4, 20])\n",
    "plt.plot()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1e4f9a51f2dbd54",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variable importance SHAP plot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "383138de3c060ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### VARIABLE IMPORTANCE\n",
    "# See more here: https://shap-lrjball.readthedocs.io/en/latest/example_notebooks/plots/bar.html\n",
    "features = [\"Number of holes, nh\", \"Web-post width, WP (mm)\",  \"Web opening diameter, Do (mm)\",  \"Ply 1 (ø)\", \"Ply 2 (ø)\", \"Ply 3 (ø)\", \"Ply 4 (ø)\", \"Ply 5 (ø)\", \"Ply 6 (ø)\", \"Ply 7 (ø)\", \"Ply 8 (ø)\"]\n",
    "\n",
    "# Create a SHAP explainer using KernelExplainer\n",
    "explainer = shap.KernelExplainer(model, shap.sample(X_train, 1))\n",
    "\n",
    "# Calculate SHAP values for the test dataset\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Reshape shap_values to remove the last dimension\n",
    "shap_values_reshaped = shap_values.reshape(X_test.shape)  # Assuming X_test.shape is (389, 11)\n",
    "\n",
    "# Visualize feature importances using bar plot\n",
    "shap.summary_plot(shap_values_reshaped, X_test, feature_names=features, plot_type=\"bar\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62738fca91bc24a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "64b3801b38e5f183",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
