{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##  A 6-Hidden Layers Architecture (Broad Search - Parametric Study)\n",
    "What is happening here?\n",
    "    [1] A deep DNN model\n",
    "    [2] Contains two lines of code to find the rsquare\n",
    "    [3] Includes lines of code on cross validation\n",
    "    [4] Include the plot of the history curves\n",
    "    \n",
    "The lower value of MAE, MSE, and RMSE implies higher accuracy of a regression model. However, a higher value of R square is considered desirable."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "254ef7c0cb13d7cf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with configuration 1: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20,  Hidden Layer 6=20\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Training model with configuration 2: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20,  Hidden Layer 6=40\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Training model with configuration 3: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20,  Hidden Layer 6=60\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Training model with configuration 4: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20,  Hidden Layer 6=80\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Training model with configuration 5: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=20,  Hidden Layer 6=100\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Training model with configuration 6: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=40,  Hidden Layer 6=20\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Training model with configuration 7: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=40,  Hidden Layer 6=40\n",
      "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step\n",
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "\u001B[1m13/13\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step \n",
      "Training model with configuration 8: Hidden Layer 1=20, Hidden Layer 2=20, Hidden Layer 3=20, Hidden Layer 4=20, Hidden Layer 5=40,  Hidden Layer 6=60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 74\u001B[0m\n\u001B[0;32m     71\u001B[0m model \u001B[38;5;241m=\u001B[39m create_model6H(p1, p2, p3, p4, p5, p6)\n\u001B[0;32m     73\u001B[0m \u001B[38;5;66;03m# Fit the model\u001B[39;00m\n\u001B[1;32m---> 74\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m150\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;66;03m# Evaluate the model on training, validation, and test sets\u001B[39;00m\n\u001B[0;32m     79\u001B[0m trainmse, trainmae \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(X_train, y_train, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Buckling_ANN_DNN\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Buckling_ANN_DNN\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:323\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[0;32m    321\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_epoch_begin(epoch)\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[1;32m--> 323\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mepoch_iterator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menumerate_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m    324\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_begin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    325\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Buckling_ANN_DNN\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:656\u001B[0m, in \u001B[0;36mTFEpochIterator.enumerate_epoch\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    654\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m step, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_iterator\n\u001B[0;32m    655\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 656\u001B[0m     iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distributed_dataset)\n\u001B[0;32m    657\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_batches:\n\u001B[0;32m    658\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\n\u001B[0;32m    659\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_batches, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps_per_execution\n\u001B[0;32m    660\u001B[0m         ):\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Buckling_ANN_DNN\\.venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:501\u001B[0m, in \u001B[0;36mDatasetV2.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mor\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minside_function():\n\u001B[0;32m    500\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[1;32m--> 501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43miterator_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOwnedIterator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    503\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.Dataset` only supports Python-style \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    504\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miteration in eager mode or within tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Buckling_ANN_DNN\\.venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:705\u001B[0m, in \u001B[0;36mOwnedIterator.__init__\u001B[1;34m(self, dataset, components, element_spec)\u001B[0m\n\u001B[0;32m    701\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (components \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m element_spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    702\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    703\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    704\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot be specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 705\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    707\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_next_call_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Buckling_ANN_DNN\\.venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:744\u001B[0m, in \u001B[0;36mOwnedIterator._create_iterator\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    741\u001B[0m   \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(fulltype\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39margs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\n\u001B[0;32m    742\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_types)\n\u001B[0;32m    743\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator_resource\u001B[38;5;241m.\u001B[39mop\u001B[38;5;241m.\u001B[39mexperimental_set_type(fulltype)\n\u001B[1;32m--> 744\u001B[0m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds_variant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ML_Buckling_ANN_DNN\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3478\u001B[0m, in \u001B[0;36mmake_iterator\u001B[1;34m(dataset, iterator, name)\u001B[0m\n\u001B[0;32m   3476\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   3477\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3478\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3479\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMakeIterator\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3480\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   3481\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np                                             \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "\n",
    "# Load the data\n",
    "bucklingdata = pd.read_csv(\"CBL_SimulationResults.csv\", encoding='cp1252')\n",
    "input_data = bucklingdata.drop(['Critical Buckling Load (N)', 'Critical Buckling Load (kN)'], axis=1)\n",
    "output_data = bucklingdata['Critical Buckling Load (kN)']\n",
    "\n",
    "# Split the data\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data,\n",
    "                                                    test_size=0.3,\n",
    "                                                    shuffle=False,\n",
    "                                                    stratify=None,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Validation data\n",
    "val_no = round(0.2 * y_train.size)\n",
    "x_val = X_train[:val_no]\n",
    "y_val = y_train[:val_no]\n",
    "\n",
    "def create_model6H(hp_layer_1, hp_layer_2, hp_layer_3, hp_layer_4, hp_layer_5, hp_layer_6):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(11,)))\n",
    "    hp_activation = 'relu'\n",
    "    hp_learning_rate = 0.001\n",
    "    model.add(Dense(hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_4, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_5, activation=hp_activation))\n",
    "    model.add(Dense(hp_layer_6, activation=hp_activation))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    # Compile your model with your optimizer, loss, and metrics\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=Adam(learning_rate = hp_learning_rate),\n",
    "                  metrics=[\"mae\"])\n",
    "    return model\n",
    "\n",
    "# Specify the range for neurons in the three hidden layers\n",
    "min_neurons = 20\n",
    "max_neurons = 100\n",
    "step = 20\n",
    "\n",
    "neuron_configs = []\n",
    "\n",
    "# Generate configurations with increasing neurons in all three layers\n",
    "for neurons1 in range(min_neurons, max_neurons + 1, step):\n",
    "    for neurons2 in range(min_neurons, max_neurons + 1, step):\n",
    "        for neurons3 in range(min_neurons, max_neurons + 1, step):\n",
    "            for neurons4 in range(min_neurons, max_neurons + 1, step):\n",
    "                for neurons5 in range(min_neurons, max_neurons + 1, step):\n",
    "                    for neurons6 in range(min_neurons, max_neurons + 1, step):\n",
    "                        neuron_configs.append((neurons1, neurons2, neurons3, neurons4, neurons5, neurons6))\n",
    "            \n",
    "results = []\n",
    "\n",
    "## Train your model for a number of epochs, with the .fit()\n",
    "## Get the performance metrics for the network and the learning curves\n",
    "# Iterate over each configuration of neurons\n",
    "for i, (p1, p2, p3, p4, p5, p6) in enumerate(neuron_configs):\n",
    "    print(f\"Training model with configuration {i+1}: Hidden Layer 1={p1}, Hidden Layer 2={p2}, Hidden Layer 3={p3}, Hidden Layer 4={p4}, Hidden Layer 5={p5},  Hidden Layer 6={p6}\")\n",
    "    \n",
    "    # Create the model for the current configuration\n",
    "    model = create_model6H(p1, p2, p3, p4, p5, p6)\n",
    "    \n",
    "    # Fit the model\n",
    "    history = model.fit(X_train, y_train, epochs=150,\n",
    "                        validation_data=(x_val, y_val), batch_size=32,\n",
    "                        verbose=0)\n",
    "    \n",
    "    # Evaluate the model on training, validation, and test sets\n",
    "    trainmse, trainmae = model.evaluate(X_train, y_train, verbose=0)\n",
    "    valmse, valmae = model.evaluate(x_val, y_val, verbose=0)\n",
    "    testmse, testmae = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Predictions for R-squared calculation\n",
    "    train_pred = model.predict(X_train)\n",
    "    val_pred = model.predict(x_val)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate R-squared scores\n",
    "    train_r2 = r2_score(y_train, train_pred)\n",
    "    val_r2 = r2_score(y_val, val_pred)\n",
    "    test_r2 = r2_score(y_test, test_pred)\n",
    "    \n",
    "    # Store the evaluation metrics in a DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        'Configuration': i + 1,\n",
    "        'Hidden Layer 1 Neurons': p1,\n",
    "        'Hidden Layer 2 Neurons': p2,\n",
    "        'Hidden Layer 3 Neurons': p3,\n",
    "        'Hidden Layer 4 Neurons': p4,\n",
    "        'Hidden Layer 5 Neurons': p5,\n",
    "        'Hidden Layer 6 Neurons': p6,\n",
    "        'Train R2': train_r2,\n",
    "        'Val R2': val_r2,\n",
    "        'Test R2': test_r2,\n",
    "        'Train RMSE': math.sqrt(trainmse),\n",
    "        'Val RMSE': math.sqrt(valmse),\n",
    "        'Test RMSE': math.sqrt(testmse),\n",
    "        'Train MAE': trainmae,\n",
    "        'Val MAE': valmae,\n",
    "        'Test MAE': testmae\n",
    "    }, index=[0])\n",
    "    \n",
    "    results.append(result_df)\n",
    "\n",
    "# Concatenate all results into a single DataFrame\n",
    "final_results = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# Save the results to an Excel file\n",
    "final_results.to_excel('6HiddenLayers_VariousNeurons_Results_1stRun.xlsx', index=False)\n",
    "\n",
    "print(f\"Results saved to 6HiddenLayers_VariousNeurons_Results.xlsx\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T18:45:02.603372Z",
     "start_time": "2024-04-14T18:41:43.255626Z"
    }
   },
   "id": "390d8b1015ba8d0d",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "### loss vs the number of epochs & MAE vs the number of epochs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46e3b0116126ea60"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def plot_loss(loss,val_loss):\n",
    "  plt.figure()\n",
    "  plt.style.use('bmh')\n",
    "  plt.grid(False)\n",
    "  plt.plot(loss, linewidth=2)\n",
    "  plt.plot(val_loss, linewidth=2)\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper right')\n",
    "  plt.show()\n",
    "\n",
    "def plot_mae(mae,val_mae):\n",
    "  plt.figure()\n",
    "  plt.style.use('ggplot')\n",
    "  plt.grid(False)\n",
    "  plt.plot(mae, linewidth=2)\n",
    "  plt.plot(val_mae, linewidth=2)\n",
    "  plt.ylabel('MAE')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper right')\n",
    "  plt.show()\n",
    "\n",
    "train_loss = (np.array(history.history[\"loss\"]))/100\n",
    "val_loss = np.array((history.history[\"val_loss\"]))/100\n",
    "\n",
    "plot_loss(train_loss, val_loss)\n",
    "plot_mae(history.history[\"mae\"], history.history[\"val_mae\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c91f49479e67a73f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlation between the actual output and the predicted output with the training dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ecad9513bef8e009"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(y_train, train_pred, s = 20, alpha=0.7, c = 'brown')\n",
    "plt.xlabel('Actual Critical Buckling Loads (kN)')\n",
    "plt.ylabel('Predicted Critical Buckling Loads (kN)')\n",
    "plt.annotate(\"R-squared = {:.3f}\".format(r2_score(y_train, train_pred)), (6, 17.5))\n",
    "plt.xlim([5, 20])\n",
    "plt.ylim([5, 20])\n",
    "plt.plot([5, 20], [5, 20])\n",
    "plt.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-12T16:22:22.149471Z"
    }
   },
   "id": "3fde11aebd540867",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Correlation between the actual output and the predicted output with the testing dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59add69d412bd5e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(style=\"ticks\", rc=custom_params)\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(y_test, test_pred, s = 20, alpha=0.7, c = 'brown')\n",
    "plt.xlabel('Actual Critical Buckling Loads (kN)')\n",
    "plt.ylabel('Predicted Critical Buckling Loads (kN)')\n",
    "plt.annotate(\"R-squared = {:.3f}\".format(r2_score(y_train, train_pred)), (5, 19))\n",
    "plt.xlim([4, 20])\n",
    "plt.ylim([4, 20])\n",
    "plt.plot([4, 20], [4, 20])\n",
    "plt.plot()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1e4f9a51f2dbd54",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variable importance SHAP plot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "383138de3c060ea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### VARIABLE IMPORTANCE\n",
    "# See more here: https://shap-lrjball.readthedocs.io/en/latest/example_notebooks/plots/bar.html\n",
    "features = [\"Number of holes, nh\", \"Web-post width, WP (mm)\",  \"Web opening diameter, Do (mm)\",  \"Ply 1 (ø)\", \"Ply 2 (ø)\", \"Ply 3 (ø)\", \"Ply 4 (ø)\", \"Ply 5 (ø)\", \"Ply 6 (ø)\", \"Ply 7 (ø)\", \"Ply 8 (ø)\"]\n",
    "\n",
    "# Create a SHAP explainer using KernelExplainer\n",
    "explainer = shap.KernelExplainer(model, shap.sample(X_train, 1))\n",
    "\n",
    "# Calculate SHAP values for the test dataset\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Reshape shap_values to remove the last dimension\n",
    "shap_values_reshaped = shap_values.reshape(X_test.shape)  # Assuming X_test.shape is (389, 11)\n",
    "\n",
    "# Visualize feature importances using bar plot\n",
    "shap.summary_plot(shap_values_reshaped, X_test, feature_names=features, plot_type=\"bar\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62738fca91bc24a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "64b3801b38e5f183",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
